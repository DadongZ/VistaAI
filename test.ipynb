{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "OPENAI_API_KEY = Config.OPENAI_API_KEY\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files=[\"./data/literature/Followon.pdf\"]).load_data()\n",
    "\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)\n",
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "vector_index.from_vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_add_nodes_to_index', '_adelete_from_docstore', '_adelete_from_index_struct', '_aget_node_with_embedding', '_async_add_nodes_to_index', '_build_index_from_nodes', '_callback_manager', '_delete_from_docstore', '_delete_from_index_struct', '_delete_node', '_docstore', '_embed_model', '_get_node_with_embedding', '_graph_store', '_index_struct', '_insert', '_insert_batch_size', '_object_map', '_show_progress', '_storage_context', '_store_nodes_override', '_transformations', '_use_async', '_vector_store', 'adelete_ref_doc', 'as_chat_engine', 'as_query_engine', 'as_retriever', 'build_index_from_nodes', 'delete', 'delete_nodes', 'delete_ref_doc', 'docstore', 'from_documents', 'from_vector_store', 'index_id', 'index_struct', 'index_struct_cls', 'insert', 'insert_nodes', 'ref_doc_info', 'refresh', 'refresh_ref_docs', 'set_index_id', 'storage_context', 'summary', 'update', 'update_ref_doc', 'vector_store']\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.storage import StorageContext\n",
    "index_path = \"./data/storage/Followon_index\"\n",
    "storage_context = StorageContext.from_defaults()\n",
    "vector_store = storage_context.vector_store.f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
